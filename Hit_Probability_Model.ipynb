{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# File: 4186993\n",
    "# Date: 10/27/2019\n",
    "# Description: This is a Random Forest Model that predicts the probability of a batted ball being a hit \n",
    "#              based on many different batted ball characteristics. This model includes a roadmap of the \n",
    "#              entire modeling building process including, data wrangling, data cleaning, model selection, \n",
    "#              variable selection, and finally model implementation.\n",
    "# Usage: File required 'Pitch_Data_v3.csv'\n",
    "# References: Ashish Kumar's Learning predictive analytics with Python 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the pitch data csv file into a pandas data frame\n",
    "data = pd.read_csv('/Users/Michael/Desktop/Pitch_Data_v3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview of the data frame to make sure the data was read correctly\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new column called Hit which states whether the batted ball was a hit or out\n",
    "# Fielding errors are considered hits in this model\n",
    "# Hit = 1, Out = 0\n",
    "\n",
    "data['Hit'] = data['h1b'] + data['h2b'] + data['h3b'] + data['hr'] + data['fieldingError']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA VISUALIZATIONS\n",
    "# 0 = Out, 1 = Hit \n",
    "\n",
    "# This is a bar chart showing the Pitch Type on the X-axis and frequency of Hits or Outs on the Y-axis\n",
    "pd.crosstab(data.PitchType,data.Hit).plot(kind='bar')\n",
    "plt.title('Pitch Type VS Hits/Outs')\n",
    "plt.xlabel('Pitch Types')\n",
    "plt.ylabel('Frequency of Hits/Outs')\n",
    "\n",
    "# This is a bar chart showing the Batter Hitting on the X-axis VS frequency of Hits or Outs on the Y-axis\n",
    "pd.crosstab(data.BatterHitting,data.Hit).plot(kind='bar')\n",
    "plt.title('Batter Hitting VS Hits/Outs')\n",
    "plt.xlabel('Batter Hitting')\n",
    "plt.ylabel('Frequency of Hits/Outs')\n",
    "\n",
    "# This is a bar chart showing the number of Strikes on the X-axis and frequency of Hits or Outs on the Y-axis\n",
    "pd.crosstab(data.Strikes,data.Hit).plot(kind='bar')\n",
    "plt.title('Strikes VS Hits/Outs')\n",
    "plt.xlabel('Number of Strikes')\n",
    "plt.ylabel('Frequency of Hits/Outs')\n",
    "\n",
    "# This is a bar chart showing the number of Balls on the X-axis and frequency of Hits or Outs on the Y-axis\n",
    "pd.crosstab(data.Balls,data.Hit).plot(kind='bar')\n",
    "plt.title('Balls VS Hits/Outs')\n",
    "plt.xlabel('Number of Balls')\n",
    "plt.ylabel('Frequency of Hits/Outs')\n",
    "\n",
    "# This is a bar chart showing the number of Outs on the X-axis and frequency of Hits or Outs on the Y-axis\n",
    "pd.crosstab(data.Outs,data.Hit).plot(kind='bar')\n",
    "plt.title('Outs VS Hits/Outs')\n",
    "plt.xlabel('Number of Outs')\n",
    "plt.ylabel('Frequency of Hits/Outs')\n",
    "\n",
    "# This is a bar chart showing whether there is a runner on base on the X-axis and frequency of Hits or Outs on the Y-axis\n",
    "pd.crosstab(data.Runners_on,data.Hit).plot(kind='bar')\n",
    "plt.title('Runners On VS Hits/Outs')\n",
    "plt.xlabel('Runners On')\n",
    "plt.ylabel('Frequency of Hits/Outs')\n",
    "\n",
    "# This is a scatterplot showing the relationship between Exit Speed and Angle\n",
    "# Scatterplot is color based if it was a hit or out\n",
    "# Purple = Out, Yellow = Hit\n",
    "area = np.pi*3\n",
    "plt.scatter(data['Angle'], data['ExitSpeed'], s=area, c=data['Hit'], alpha=0.5)\n",
    "plt.title('ExitSpeed Vs Angle')\n",
    "plt.xlabel('Angle')\n",
    "plt.ylabel('Exitspeed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a histogram showing the distribution shape of Pitch Speed in MPH\n",
    "data.StartSpeed.hist()\n",
    "plt.title('Histogram of Pitch Speed (MPH)')\n",
    "plt.xlabel('Pitch Speed')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a histogram showing the distribution shape of Exit Speed in MPH\n",
    "data.ExitSpeed.hist()\n",
    "plt.title('Histogram of Exit Speed (MPH)')\n",
    "plt.xlabel('Exit Speed')\n",
    "plt.ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing target variable\n",
    "# Counts and shows how many hits and outs are in the data frame\n",
    "# 0 = Out, 1 = Hit\n",
    "\n",
    "data['Hit'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the percent of Outs in the \"Hit\" column \n",
    "# Calculates the percent of Hits in the \"Hit\" column\n",
    "# Shows the imbalance in the target variable\n",
    "\n",
    "hit = len(data[data['Hit']==1])\n",
    "no_hit = len(data[data['Hit']==0])\n",
    "pct_no_hit = no_hit/(no_hit+hit)\n",
    "pct_hit = hit/(no_hit+hit)\n",
    "print(\"Percentage of hits\", pct_hit*100)\n",
    "print(\"Percentage of outs\", pct_no_hit*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar chart showing the unequal count of Outs vs Hits in the data frame\n",
    "\n",
    "data['Hit'].value_counts().plot(kind='bar',figsize=(10,8),title=\"Number of hits\",)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the function get_dummies to create 'dummy' variables based on the categorical features of \n",
    "# PitchType column in the dataset. This creates a new column for each type of pitch \n",
    "\n",
    "dummy_ranks = pd.get_dummies(data['PitchType'], prefix='pitch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joining the dummy variables for PitchType back onto our original dataset\n",
    "\n",
    "data = data.join(dummy_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the columns that are not relevant to a batted ball being a hit or an out\n",
    "# Columns were dropped based on my own person playing experience and knowledge\n",
    "# Columns calledStrike, swing, swingStrike, foul, hbp, and inPlay were dropped because every ball in the dataset was put into play making those columns useless information\n",
    "# Columns h1b, h2b, h3b, hr, and fieldingError were dropped because those were combined into the 'Hit' column because we only care if it was a hit or out, not what type of hit\n",
    "# inPlayOut was dropped and replaced by new 'Hit' column\n",
    "# PitchType was dropped because we created new dummy variable columns in replace for this column\n",
    "# PinchHit was dropped because there are 0 pinch hits in this dataset\n",
    "\n",
    "data = data.drop(columns=['GameId', 'BallparkId','GameEventId','GameTime','Season','AtBatId','TrackManUid','BatterId',\n",
    "                         'BatterPositionId','PitcherId','CatcherId','HomeTeamId','AwayTeamId','Inning','InningTop',\n",
    "                         'calledStrike','swing','swingStrike','foul','inPlay','h1b','h2b','h3b','hr','hbp',\n",
    "                         'fieldingError','BatterHeight','PitcherHeight', 'inPlayOut', 'PitchType','PinchHit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding out if there are any null values in the data frame\n",
    "\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing the null values from the data frame\n",
    "# Decided to remove the null value from the data frame because we have such a large number of observations still without the null values\n",
    "\n",
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the data type of BatterHitting and PitcherThrowing to a category for easier manipulation\n",
    "\n",
    "data[\"BatterHitting\"] = data[\"BatterHitting\"].astype('category')\n",
    "data[\"PitcherThrowing\"] = data[\"PitcherThrowing\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning a numeric value to the corresponding category for both pitchers and hitters\n",
    "# L = 0, R = 1\n",
    "# After assigning 0 or 1 based on pitching or hitting side it puts it back into the original data columns\n",
    "\n",
    "data[\"BatterHitting\"] = data[\"BatterHitting\"].cat.codes\n",
    "data[\"PitcherThrowing\"] = data[\"PitcherThrowing\"].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the Z-scores for each of the non-categorical columns in the data frame in order to spot outliers\n",
    "# Z-score calculates how many standard deviations that number is away from the mean\n",
    "# Puts the calculated Z-scores into new columns in the data frame\n",
    "\n",
    "data['batterTimesFaced_Zscore'] = np.abs(stats.zscore(data['batterTimesFaced'], axis=0))\n",
    "data['cumulativeBattersFaced_Zscore'] = np.abs(stats.zscore(data['cumulativeBattersFaced'], axis=0))\n",
    "data['PlateAppearance_Zscore'] = np.abs(stats.zscore(data['PlateAppearance'], axis=0))\n",
    "data['PitchOfPA_Zscore'] = np.abs(stats.zscore(data['PitchOfPA'], axis=0))\n",
    "data['VertBreak_Zscore'] = np.abs(stats.zscore(data['VertBreak'], axis=0))\n",
    "data['StartSpeed_Zscore'] = np.abs(stats.zscore(data['StartSpeed'], axis=0))\n",
    "data['Px_Zscore'] = np.abs(stats.zscore(data['Px'], axis=0))\n",
    "data['Pz_Zscore'] = np.abs(stats.zscore(data['Pz'], axis=0))\n",
    "data['RelHeight_Zscore'] = np.abs(stats.zscore(data['RelHeight'], axis=0))\n",
    "data['RelSide_Zscore'] = np.abs(stats.zscore(data['RelSide'], axis=0))\n",
    "data['Extension_Zscore'] = np.abs(stats.zscore(data['Extension'], axis=0))\n",
    "data['VertRelAngle_Zscore'] = np.abs(stats.zscore(data['VertRelAngle'], axis=0))\n",
    "data['HorzRelAngle_Zscore'] = np.abs(stats.zscore(data['HorzRelAngle'], axis=0))\n",
    "data['SpinRate_Zscore'] = np.abs(stats.zscore(data['SpinRate'], axis=0))\n",
    "data['SpinAxis_Zscore'] = np.abs(stats.zscore(data['SpinAxis'], axis=0))\n",
    "data['ExitSpeed_Zscore'] = np.abs(stats.zscore(data['ExitSpeed'], axis=0))\n",
    "data['Angle_Zscore'] = np.abs(stats.zscore(data['Angle'], axis=0))\n",
    "data['Bearing_Zscore'] = np.abs(stats.zscore(data['Bearing'], axis=0))\n",
    "data['Direction_Zscore'] = np.abs(stats.zscore(data['Direction'], axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drops the rows where outliers are present\n",
    "# Outlier is defined as being greater than or equal to 3 standard deviations from the mean\n",
    "\n",
    "data.drop(data.index[data['batterTimesFaced_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['cumulativeBattersFaced_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['PlateAppearance_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['PitchOfPA_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['VertBreak_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['StartSpeed_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['Px_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['Pz_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['RelHeight_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['RelSide_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['Extension_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['VertRelAngle_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['HorzRelAngle_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['SpinRate_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['SpinAxis_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['ExitSpeed_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['Angle_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['Bearing_Zscore'] >= 3], inplace = True)\n",
    "data.drop(data.index[data['Direction_Zscore'] >= 3], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removes the Z-score columns from the data frame now that the outliers are found and removed\n",
    "\n",
    "data = data.drop(columns=['batterTimesFaced_Zscore','cumulativeBattersFaced_Zscore','PlateAppearance_Zscore',\n",
    "                          'PitchOfPA_Zscore','VertBreak_Zscore','StartSpeed_Zscore','Px_Zscore','Pz_Zscore',\n",
    "                         'RelHeight_Zscore','RelSide_Zscore','Extension_Zscore','VertRelAngle_Zscore',\n",
    "                         'HorzRelAngle_Zscore','SpinRate_Zscore','SpinAxis_Zscore','ExitSpeed_Zscore','Angle_Zscore',\n",
    "                         'Bearing_Zscore','Direction_Zscore'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = Creates a new data frame (X) from original data frame with all columns besides 'Hit' column\n",
    "# y = Creates a new data frame (y) from original data frame with ONLY the 'Hit' column, dropping all other columns\n",
    "\n",
    "X = data.loc[:, data.columns != 'Hit']\n",
    "y = data.loc[:, data.columns == 'Hit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Because the data frame is imbalanced with much more Outs (0) than Hits (1) I implemented SMOTENC to over-sample and \n",
    "balance the data. SMOTENC or Synthetic Minority Over-sampling Technique for Nominal and Continuous works by finding \n",
    "two near neighbors in a minority class, producing a new point midway between the two existing points and adding that \n",
    "new point into the sample. This will make the proportion of Hits equal to the proportion of Outs.\n",
    "\"\"\"\n",
    "# Columns 0,1,2,3,4,5,6,7,8,9,10,27,28,29,30,31,32,33,34 are the categorical features which SMOTENC allows us to use\n",
    "# After the SMOTENC test is fit to the data it is put in new variables called sample_data_X and sample_data_y\n",
    "# sample_data_X contains the new balanced data with every column besides 'Hit'\n",
    "# sample_data_y contains the new balanced data with only the 'Hit' column\n",
    "\n",
    "smote = SMOTENC(categorical_features=[0,1,2,3,4,5,6,7,8,9,26,27,28,29,30,31,32,33], random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "columns = X.columns\n",
    "sample_data_X,sample_data_y=smote.fit_sample(X_train, y_train)\n",
    "sample_data_X = pd.DataFrame(data=sample_data_X,columns=columns )\n",
    "sample_data_y= pd.DataFrame(data=sample_data_y,columns=['Hit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing to see if the SMOTENC function worked at balancing the proportion of Hits and Outs\n",
    "# Prints the length of the new sampled balanced dataset\n",
    "# Shows that the number of Outs and the number of Hits are equal\n",
    "# Shows that the proportion of Outs and Hits are equal\n",
    "\n",
    "print(\"Length of new sampled data is \", len(sample_data_X))\n",
    "print(\"Number of outs in new sampled data\", len(sample_data_y[sample_data_y['Hit']==0]))\n",
    "print(\"Number of hits in new sampled data\",len(sample_data_y[sample_data_y['Hit']==1]))\n",
    "print(\"Proportion of outs data in new sampled data is \", len(sample_data_y[sample_data_y['Hit']==0])/len(sample_data_X))\n",
    "print(\"Proportion of hits data in new sampled data is \",len(sample_data_y[sample_data_y['Hit']==1])/len(sample_data_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to see if we have unique values in the dummie columns we created for PitchType\n",
    "# 'pitch_KN' is only showing one unique value of 0, meaning that pitch was never thrown in our new sampled dataset\n",
    "\n",
    "print(sample_data_X['pitch_CB'].unique())\n",
    "print(sample_data_X['pitch_CH'].unique())\n",
    "print(sample_data_X['pitch_CT'].unique())\n",
    "print(sample_data_X['pitch_FB'].unique())\n",
    "print(sample_data_X['pitch_KN'].unique())\n",
    "print(sample_data_X['pitch_SI'].unique())\n",
    "print(sample_data_X['pitch_SL'].unique())\n",
    "print(sample_data_X['pitch_SP'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping the 'pitch_KN' column because it was never thrown in our balanced sample dataset\n",
    "\n",
    "sample_data_X = sample_data_X.drop(columns='pitch_KN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "RFE or Recursive feature elimination is a feature selection method that fits the model and removes the \n",
    "weakest features until the specified number of features is reached according to the f1 weighted score\n",
    "RFE will tell me how many and what features are the most important for classifying the 'Hit' column\n",
    "\"\"\"\n",
    "\n",
    "#rfc = RandomForestClassifier(random_state=42)\n",
    "#rfecv = RFECV(rfc, cv=3, scoring='f1_weighted')\n",
    "#rfecv.fit(sample_data_X, sample_data_y)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows each step in the feature elimination method and what the corresponding f1-weighted score is\n",
    "#print('Grid-Scores:','\\n',(rfecv.grid_scores_),'\\n')\n",
    "\n",
    "# Tells you the number of features the model should include to achieve the highest f1-weighted score\n",
    "#print('Number of viable features:',(rfecv.n_features_),'\\n')\n",
    "\n",
    "# Prints out a list of numbers that shows what variables should or shouldn't be in the model\n",
    "# 1 = strong fitting variable (KEEP), >1 = weak fitting variable (REMOVE)\n",
    "#print('Feature Ranking:',(rfecv.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a line plot showing the relationship between Grid-Score and Number of Features Selected\n",
    "# Shows how increasing the number of features will increase the Grid-Score of the model\n",
    "# Graph also verifies the optimal number of features to indeed be at 9 features\n",
    "\n",
    "#plt.figure()\n",
    "#plt.xlabel(\"Number of Features Selected\")\n",
    "#plt.ylabel(\"Accuracy\")\n",
    "#plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FRE test concluded weakest features in the model to be all besides the columns in the 'cols' variable\n",
    "# Creating a new columns variable that include only the 9 most important columns according to the FRE test\n",
    "# Putting sample data with new columns in variable 'X'\n",
    "# Putting sample data with only 'Hit' column in variable 'y'\n",
    "\n",
    "cols = ['HorzBreak', 'Px','Pz','HorzRelAngle', 'SpinRate','ExitSpeed', 'Angle','Bearing','Direction' ]\n",
    "X=sample_data_X[cols]\n",
    "y=sample_data_y['Hit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing a Random Forest Classification Model on the now treated and clean dataset\n",
    "# Splitting the dataset up into a train and test dataset in order to train the model with train dataset and test how well the model is with the test dataset \n",
    "# 70% of the data is in the training set and 30% in testing set\n",
    "# random_state=42 allows for the randomness to be equal throughout the model\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates the accuracy score the model had at classifying 'Hit' in the test dataset\n",
    "\n",
    "rfc_predict = rfc.predict(X_test)\n",
    "print('Random Forest Accuracy Score: {}'.format(rfc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a confusion matrix which states how many hits/outs the model correctly classified\n",
    "# Confusion matrix is read like the following:\n",
    "#  True Negative|False Negative\n",
    "# False Positive|True Positive\n",
    "labels = [0,1]\n",
    "confusion_matrix = confusion_matrix(y_test, rfc_predict,labels)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a summary of how well the model did at classifying hit or out\n",
    "# Model can classify if the pitch was a hit or out with 82% accuracy\n",
    "# 0 = Out, 1 = Hit\n",
    "\n",
    "print(classification_report(y_test, rfc_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
